{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "497c473f-aa83-4f78-92ff-b3eb701dc956",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c29330d1-38d7-42f1-87da-a2aecc548354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a0cd4e-49c2-44a3-96d4-94a93f68c3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 11:31:31.758703: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-08 11:31:31.780273: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-08 11:31:31.780292: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-08 11:31:31.780836: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-08 11:31:31.784560: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-08 11:31:32.207549: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eadac52-eca1-4424-a039-ef56471b3924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b974436-505a-47ae-9a11-f27677e3de2f",
   "metadata": {},
   "source": [
    "### Environment with Random Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa76096-3d35-47cf-b98e-1a63bb6be249",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v0'\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "232d0956-4810-4ce1-81f8-523b29ef3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49431c0a-dafe-4fc2-9905-880e8a5d33db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1 Score:  18.0\n",
      "Episode:  2 Score:  24.0\n",
      "Episode:  3 Score:  13.0\n",
      "Episode:  4 Score:  42.0\n",
      "Episode:  5 Score:  12.0\n",
      "Episode:  6 Score:  31.0\n",
      "Episode:  7 Score:  35.0\n",
      "Episode:  8 Score:  11.0\n",
      "Episode:  9 Score:  46.0\n",
      "Episode:  10 Score:  20.0\n"
     ]
    }
   ],
   "source": [
    "for episode in range(1, 11):\n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "    done=False\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode: ', episode, 'Score: ', score)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ea4b6-3131-48af-b4fd-257a5e8e9364",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e10909c-06b6-4c2d-9420-7f8eb1533955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9504173d-893d-41e3-be2c-3baa8b4eee7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1678 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1556       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00873783 |\n",
      "|    clip_fraction        | 0.0953     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.686     |\n",
      "|    explained_variance   | 0.000216   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.04       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    value_loss           | 49.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1549        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009741323 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 40.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1536        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007813348 |\n",
      "|    clip_fraction        | 0.0698      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.639      |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 60          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1540        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009033681 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.611      |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 70          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1539        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011655144 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.605      |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1542        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004939116 |\n",
      "|    clip_fraction        | 0.0274      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.583      |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    value_loss           | 79.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1545        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004749035 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.559      |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    value_loss           | 66.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1545         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032571433 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.571       |\n",
      "|    explained_variance   | 0.84         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.79         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00469     |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1544         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033766583 |\n",
      "|    clip_fraction        | 0.0415       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.568       |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.04         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0094      |\n",
      "|    value_loss           | 20.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1544        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003755595 |\n",
      "|    clip_fraction        | 0.033       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.55       |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.84        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7fd172680e80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=21000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeeafe1d-7f74-4a95-837c-ffb5aa87fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store my model\n",
    "model.save('my_first_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd09f751-01fa-4562-a54f-7b18979913b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/me/.local/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200.0, 0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0081d83-a45d-4e3b-a73b-6387f3017a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c551a0c2-bff5-4519-9a39-81f0f3dd0b62",
   "metadata": {},
   "source": [
    "### Evaluation the actions based on the trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2311915-22db-46f7-a10d-6dda510c5f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1 Score:  0\n",
      "Episode:  2 Score:  0\n",
      "Episode:  3 Score:  0\n",
      "Episode:  4 Score:  0\n",
      "Episode:  5 Score:  0\n",
      "Episode:  6 Score:  0\n",
      "Episode:  7 Score:  0\n",
      "Episode:  8 Score:  0\n",
      "Episode:  9 Score:  0\n",
      "Episode:  10 Score:  0\n"
     ]
    }
   ],
   "source": [
    "# Little modification needed to acheive better result on the test\n",
    "\n",
    "for episode in range(1, 11):\n",
    "    score = 0\n",
    "    obs = env.reset()\n",
    "    doen = False\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode: ', episode, 'Score: ', score)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0de8d9-f23f-47e2-b61d-ede545023819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a1ff10-b767-4ecb-b283-2eeaa837ca50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69e5d2-4cb5-465e-bdd3-a4cf77df5b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
