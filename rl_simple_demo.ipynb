{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "497c473f-aa83-4f78-92ff-b3eb701dc956",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c29330d1-38d7-42f1-87da-a2aecc548354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a0cd4e-49c2-44a3-96d4-94a93f68c3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 11:54:42.621465: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-08 11:54:42.643635: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-08 11:54:42.643657: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-08 11:54:42.644211: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-08 11:54:42.647952: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-08 11:54:43.086208: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eadac52-eca1-4424-a039-ef56471b3924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b974436-505a-47ae-9a11-f27677e3de2f",
   "metadata": {},
   "source": [
    "### Environment with Random Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa76096-3d35-47cf-b98e-1a63bb6be249",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v0'\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "232d0956-4810-4ce1-81f8-523b29ef3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49431c0a-dafe-4fc2-9905-880e8a5d33db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1 Score:  16.0\n",
      "Episode:  2 Score:  18.0\n",
      "Episode:  3 Score:  31.0\n",
      "Episode:  4 Score:  28.0\n",
      "Episode:  5 Score:  20.0\n",
      "Episode:  6 Score:  23.0\n",
      "Episode:  7 Score:  14.0\n",
      "Episode:  8 Score:  34.0\n",
      "Episode:  9 Score:  26.0\n",
      "Episode:  10 Score:  15.0\n",
      "Episode:  11 Score:  37.0\n",
      "Episode:  12 Score:  13.0\n",
      "Episode:  13 Score:  19.0\n",
      "Episode:  14 Score:  26.0\n",
      "Episode:  15 Score:  27.0\n",
      "Episode:  16 Score:  25.0\n",
      "Episode:  17 Score:  18.0\n",
      "Episode:  18 Score:  53.0\n",
      "Episode:  19 Score:  64.0\n",
      "Episode:  20 Score:  17.0\n",
      "Episode:  21 Score:  25.0\n",
      "Episode:  22 Score:  14.0\n",
      "Episode:  23 Score:  15.0\n",
      "Episode:  24 Score:  30.0\n",
      "Episode:  25 Score:  21.0\n",
      "Episode:  26 Score:  45.0\n",
      "Episode:  27 Score:  37.0\n",
      "Episode:  28 Score:  12.0\n",
      "Episode:  29 Score:  17.0\n",
      "Episode:  30 Score:  30.0\n",
      "Episode:  31 Score:  23.0\n",
      "Episode:  32 Score:  22.0\n",
      "Episode:  33 Score:  9.0\n",
      "Episode:  34 Score:  10.0\n",
      "Episode:  35 Score:  47.0\n",
      "Episode:  36 Score:  23.0\n",
      "Episode:  37 Score:  21.0\n",
      "Episode:  38 Score:  23.0\n",
      "Episode:  39 Score:  27.0\n",
      "Episode:  40 Score:  20.0\n",
      "Episode:  41 Score:  17.0\n",
      "Episode:  42 Score:  9.0\n",
      "Episode:  43 Score:  29.0\n",
      "Episode:  44 Score:  23.0\n",
      "Episode:  45 Score:  16.0\n",
      "Episode:  46 Score:  23.0\n",
      "Episode:  47 Score:  17.0\n",
      "Episode:  48 Score:  12.0\n",
      "Episode:  49 Score:  17.0\n",
      "Episode:  50 Score:  17.0\n",
      "Episode:  51 Score:  21.0\n",
      "Episode:  52 Score:  28.0\n",
      "Episode:  53 Score:  13.0\n",
      "Episode:  54 Score:  17.0\n",
      "Episode:  55 Score:  25.0\n",
      "Episode:  56 Score:  19.0\n",
      "Episode:  57 Score:  15.0\n",
      "Episode:  58 Score:  22.0\n",
      "Episode:  59 Score:  27.0\n",
      "Episode:  60 Score:  35.0\n",
      "Episode:  61 Score:  24.0\n",
      "Episode:  62 Score:  31.0\n",
      "Episode:  63 Score:  13.0\n",
      "Episode:  64 Score:  22.0\n",
      "Episode:  65 Score:  26.0\n",
      "Episode:  66 Score:  23.0\n",
      "Episode:  67 Score:  11.0\n",
      "Episode:  68 Score:  20.0\n",
      "Episode:  69 Score:  37.0\n",
      "Episode:  70 Score:  23.0\n",
      "Episode:  71 Score:  42.0\n",
      "Episode:  72 Score:  13.0\n",
      "Episode:  73 Score:  12.0\n",
      "Episode:  74 Score:  20.0\n",
      "Episode:  75 Score:  13.0\n",
      "Episode:  76 Score:  31.0\n",
      "Episode:  77 Score:  22.0\n",
      "Episode:  78 Score:  17.0\n",
      "Episode:  79 Score:  9.0\n",
      "Episode:  80 Score:  22.0\n",
      "Episode:  81 Score:  12.0\n",
      "Episode:  82 Score:  13.0\n",
      "Episode:  83 Score:  19.0\n",
      "Episode:  84 Score:  33.0\n",
      "Episode:  85 Score:  58.0\n",
      "Episode:  86 Score:  39.0\n",
      "Episode:  87 Score:  24.0\n",
      "Episode:  88 Score:  18.0\n",
      "Episode:  89 Score:  12.0\n",
      "Episode:  90 Score:  21.0\n",
      "Episode:  91 Score:  13.0\n",
      "Episode:  92 Score:  50.0\n",
      "Episode:  93 Score:  28.0\n",
      "Episode:  94 Score:  35.0\n",
      "Episode:  95 Score:  28.0\n",
      "Episode:  96 Score:  13.0\n",
      "Episode:  97 Score:  19.0\n",
      "Episode:  98 Score:  18.0\n",
      "Episode:  99 Score:  20.0\n",
      "Episode:  100 Score:  13.0\n"
     ]
    }
   ],
   "source": [
    "for episode in range(1, 101):\n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "    done=False\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode: ', episode, 'Score: ', score)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ea4b6-3131-48af-b4fd-257a5e8e9364",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e10909c-06b6-4c2d-9420-7f8eb1533955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9504173d-893d-41e3-be2c-3baa8b4eee7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1642 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1521        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008431757 |\n",
      "|    clip_fraction        | 0.0798      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | -0.00108    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.28        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 48.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1499        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009497649 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.669      |\n",
      "|    explained_variance   | 0.0972      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1504        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007674822 |\n",
      "|    clip_fraction        | 0.0731      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.635      |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 54          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1502        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010511477 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.603      |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 60.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1500         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064731864 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.592       |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 25.6         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    value_loss           | 56.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1497         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042655687 |\n",
      "|    clip_fraction        | 0.0358       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.57        |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00857     |\n",
      "|    value_loss           | 59           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1491        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004522171 |\n",
      "|    clip_fraction        | 0.0117      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.564      |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.9         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006908542 |\n",
      "|    clip_fraction        | 0.0267      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.565      |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.99        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1486         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058880555 |\n",
      "|    clip_fraction        | 0.033        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.552       |\n",
      "|    explained_variance   | 0.921        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.468        |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    value_loss           | 12.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1485         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043408656 |\n",
      "|    clip_fraction        | 0.0403       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.55        |\n",
      "|    explained_variance   | 0.837        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.601        |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    value_loss           | 9.32         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f8fdecd1390>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=21000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeeafe1d-7f74-4a95-837c-ffb5aa87fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store my model\n",
    "model.save('my_first_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd09f751-01fa-4562-a54f-7b18979913b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/me/.local/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200.0, 0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0081d83-a45d-4e3b-a73b-6387f3017a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c551a0c2-bff5-4519-9a39-81f0f3dd0b62",
   "metadata": {},
   "source": [
    "### Evaluation the actions based on the trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2311915-22db-46f7-a10d-6dda510c5f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1 Score:  0\n",
      "Episode:  2 Score:  0\n",
      "Episode:  3 Score:  0\n",
      "Episode:  4 Score:  0\n",
      "Episode:  5 Score:  0\n",
      "Episode:  6 Score:  0\n",
      "Episode:  7 Score:  0\n",
      "Episode:  8 Score:  0\n",
      "Episode:  9 Score:  0\n",
      "Episode:  10 Score:  0\n",
      "Episode:  11 Score:  0\n",
      "Episode:  12 Score:  0\n",
      "Episode:  13 Score:  0\n",
      "Episode:  14 Score:  0\n",
      "Episode:  15 Score:  0\n",
      "Episode:  16 Score:  0\n",
      "Episode:  17 Score:  0\n",
      "Episode:  18 Score:  0\n",
      "Episode:  19 Score:  0\n",
      "Episode:  20 Score:  0\n",
      "Episode:  21 Score:  0\n",
      "Episode:  22 Score:  0\n",
      "Episode:  23 Score:  0\n",
      "Episode:  24 Score:  0\n",
      "Episode:  25 Score:  0\n",
      "Episode:  26 Score:  0\n",
      "Episode:  27 Score:  0\n",
      "Episode:  28 Score:  0\n",
      "Episode:  29 Score:  0\n",
      "Episode:  30 Score:  0\n",
      "Episode:  31 Score:  0\n",
      "Episode:  32 Score:  0\n",
      "Episode:  33 Score:  0\n",
      "Episode:  34 Score:  0\n",
      "Episode:  35 Score:  0\n",
      "Episode:  36 Score:  0\n",
      "Episode:  37 Score:  0\n",
      "Episode:  38 Score:  0\n",
      "Episode:  39 Score:  0\n",
      "Episode:  40 Score:  0\n",
      "Episode:  41 Score:  0\n",
      "Episode:  42 Score:  0\n",
      "Episode:  43 Score:  0\n",
      "Episode:  44 Score:  0\n",
      "Episode:  45 Score:  0\n",
      "Episode:  46 Score:  0\n",
      "Episode:  47 Score:  0\n",
      "Episode:  48 Score:  0\n",
      "Episode:  49 Score:  0\n",
      "Episode:  50 Score:  0\n",
      "Episode:  51 Score:  0\n",
      "Episode:  52 Score:  0\n",
      "Episode:  53 Score:  0\n",
      "Episode:  54 Score:  0\n",
      "Episode:  55 Score:  0\n",
      "Episode:  56 Score:  0\n",
      "Episode:  57 Score:  0\n",
      "Episode:  58 Score:  0\n",
      "Episode:  59 Score:  0\n",
      "Episode:  60 Score:  0\n",
      "Episode:  61 Score:  0\n",
      "Episode:  62 Score:  0\n",
      "Episode:  63 Score:  0\n",
      "Episode:  64 Score:  0\n",
      "Episode:  65 Score:  0\n",
      "Episode:  66 Score:  0\n",
      "Episode:  67 Score:  0\n",
      "Episode:  68 Score:  0\n",
      "Episode:  69 Score:  0\n",
      "Episode:  70 Score:  0\n",
      "Episode:  71 Score:  0\n",
      "Episode:  72 Score:  0\n",
      "Episode:  73 Score:  0\n",
      "Episode:  74 Score:  0\n",
      "Episode:  75 Score:  0\n",
      "Episode:  76 Score:  0\n",
      "Episode:  77 Score:  0\n",
      "Episode:  78 Score:  0\n",
      "Episode:  79 Score:  0\n",
      "Episode:  80 Score:  0\n",
      "Episode:  81 Score:  0\n",
      "Episode:  82 Score:  0\n",
      "Episode:  83 Score:  0\n",
      "Episode:  84 Score:  0\n",
      "Episode:  85 Score:  0\n",
      "Episode:  86 Score:  0\n",
      "Episode:  87 Score:  0\n",
      "Episode:  88 Score:  0\n",
      "Episode:  89 Score:  0\n",
      "Episode:  90 Score:  0\n",
      "Episode:  91 Score:  0\n",
      "Episode:  92 Score:  0\n",
      "Episode:  93 Score:  0\n",
      "Episode:  94 Score:  0\n",
      "Episode:  95 Score:  0\n",
      "Episode:  96 Score:  0\n",
      "Episode:  97 Score:  0\n",
      "Episode:  98 Score:  0\n",
      "Episode:  99 Score:  0\n",
      "Episode:  100 Score:  0\n",
      "Episode:  101 Score:  0\n",
      "Episode:  102 Score:  0\n",
      "Episode:  103 Score:  0\n",
      "Episode:  104 Score:  0\n",
      "Episode:  105 Score:  0\n",
      "Episode:  106 Score:  0\n",
      "Episode:  107 Score:  0\n",
      "Episode:  108 Score:  0\n",
      "Episode:  109 Score:  0\n",
      "Episode:  110 Score:  0\n",
      "Episode:  111 Score:  0\n",
      "Episode:  112 Score:  0\n",
      "Episode:  113 Score:  0\n",
      "Episode:  114 Score:  0\n",
      "Episode:  115 Score:  0\n",
      "Episode:  116 Score:  0\n",
      "Episode:  117 Score:  0\n",
      "Episode:  118 Score:  0\n",
      "Episode:  119 Score:  0\n",
      "Episode:  120 Score:  0\n"
     ]
    }
   ],
   "source": [
    "# Little modification needed to acheive better result on the test\n",
    "\n",
    "for episode in range(1, 121):\n",
    "    score = 0\n",
    "    obs = env.reset()\n",
    "    doen = False\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode: ', episode, 'Score: ', score)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0de8d9-f23f-47e2-b61d-ede545023819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a1ff10-b767-4ecb-b283-2eeaa837ca50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69e5d2-4cb5-465e-bdd3-a4cf77df5b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
